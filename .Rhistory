store.logl[i]=sum(logl)
store.z[i,]=z
store.gamma[i]=gamma1
}
traceback()
#useful pre-calculated quantities
nloc=nrow(dat)
nspp=ncol(dat)
nl.mat=matrix(nl,nloc,nspp)
n.minus.y=nl.mat-dat
constant=nspp*(lgamma(a.prior+b.prior)-lgamma(a.prior)-lgamma(b.prior))
#initial parameter values
z=sample(1:ngroup,size=nloc,replace=T)
theta=rep(1/ngroup,ngroup)
tmp=runif(ngroup*nspp)
phi=matrix(tmp,ngroup,nspp)
gamma1=0.1
gamma.possib=seq(from=0.1,to=1,by=0.05) #possible values for gamma
#to store results from gibbs sampler
store.phi=matrix(NA,ngibbs,nspp*ngroup)
store.theta=matrix(NA,ngibbs,ngroup)
store.z=matrix(NA,ngibbs,nloc)
store.gamma=matrix(NA,ngibbs,1)
store.logl=rep(NA,ngibbs)
i=1
z=update.z(dat=dat,nl=nl,n.minus.y=n.minus.y,phi=phi,theta=theta,
ngroup=ngroup,nloc=nloc,nspp=nspp,z=z,
a.prior=a.prior,b.prior=b.prior)
#re-order groups if necessary
#summarize the data
#determine the number of times a particular species was observed in each location group. This is ncs1
#determine the number of times a particular species was not observed in each location group. This is ncs0
tmp=ncs(dat=dat,nminusy=n.minus.y,z=z-1,nspp=nspp,nloc=nloc,ngroup=ngroup)
#sample the phi matrix containing the spp composition characterization of each group of locations
phi=matrix(rbeta(ngroup*nspp,tmp$ncs1+a.prior,tmp$ncs0+b.prior),ngroup,nspp)
#sample v and theta (this might also result in changes for z and phi)
tmp=update.theta(z=z,ngroup=ngroup,gamma1=gamma1,burnin=burnin,gibbs.step=i,theta=theta,phi=phi)
theta=tmp$theta
z=tmp$z
v=tmp$v
phi=tmp$phi
#sample the TSB parameter gamma
gamma1=sample.gamma(v=v,ngroup=ngroup,gamma.possib=gamma.possib)
#get loglikelihood
prob=phi[z,]
logl=dbinom(dat,size=nl.mat,prob=prob,log=T)
#store results
store.phi[i,]=phi
store.theta[i,]=theta
store.logl[i]=sum(logl)
store.z[i,]=z
store.gamma[i]=gamma1
#useful pre-calculated quantities
nloc=nrow(dat)
nspp=ncol(dat)
nl.mat=matrix(nl,nloc,nspp)
n.minus.y=nl.mat-dat
constant=nspp*(lgamma(a.prior+b.prior)-lgamma(a.prior)-lgamma(b.prior))
#initial parameter values
z=sample(1:ngroup,size=nloc,replace=T)
theta=rep(1/ngroup,ngroup)
tmp=runif(ngroup*nspp)
phi=matrix(tmp,ngroup,nspp)
gamma1=0.1
gamma.possib=seq(from=0.1,to=1,by=0.05) #possible values for gamma
#to store results from gibbs sampler
store.phi=matrix(NA,ngibbs,nspp*ngroup)
store.theta=matrix(NA,ngibbs,ngroup)
store.z=matrix(NA,ngibbs,nloc)
store.gamma=matrix(NA,ngibbs,1)
store.logl=rep(NA,ngibbs)
#run gibbs sampler
for (i in 1:ngibbs){
print(i)
#sample group allocation vector z
z=update.z(dat=dat,nl=nl,n.minus.y=n.minus.y,phi=phi,theta=theta,
ngroup=ngroup,nloc=nloc,nspp=nspp,z=z,
a.prior=a.prior,b.prior=b.prior,constant=constant)
#re-order groups if necessary
#summarize the data
#determine the number of times a particular species was observed in each location group. This is ncs1
#determine the number of times a particular species was not observed in each location group. This is ncs0
tmp=ncs(dat=dat,nminusy=n.minus.y,z=z-1,nspp=nspp,nloc=nloc,ngroup=ngroup)
#sample the phi matrix containing the spp composition characterization of each group of locations
phi=matrix(rbeta(ngroup*nspp,tmp$ncs1+a.prior,tmp$ncs0+b.prior),ngroup,nspp)
#sample v and theta (this might also result in changes for z and phi)
tmp=update.theta(z=z,ngroup=ngroup,gamma1=gamma1,burnin=burnin,gibbs.step=i,theta=theta,phi=phi)
theta=tmp$theta
z=tmp$z
v=tmp$v
phi=tmp$phi
#sample the TSB parameter gamma
gamma1=sample.gamma(v=v,ngroup=ngroup,gamma.possib=gamma.possib)
#get loglikelihood
prob=phi[z,]
logl=dbinom(dat,size=nl.mat,prob=prob,log=T)
#store results
store.phi[i,]=phi
store.theta[i,]=theta
store.logl[i]=sum(logl)
store.z[i,]=z
store.gamma[i]=gamma1
}
table(z)
z=update.z(dat=dat,nl=nl,n.minus.y=n.minus.y,phi=phi,theta=theta,
ngroup=ngroup,nloc=nloc,nspp=nspp,z=z,
a.prior=a.prior,b.prior=b.prior,constant=constant)
log.theta=log(theta)
log.phi=log(phi)
log.one.minus.phi=log(1-phi)
#calculate the log probability for each group that already exists
prior.prob=rowSums(dbeta(phi,a.prior,b.prior,log=T))
tmp=matrix(NA,nloc,ngroup)
for (i in 1:ngroup){
rasc=dat*matrix(log.phi[i,],nloc,nspp,byrow=T)+
n.minus.y*matrix(log.one.minus.phi[i,],nloc,nspp,byrow=T)
tmp[,i]=rowSums(rasc)+prior.prob[i]+log.theta[i] #sum log of prior probability
}
tmp
tmp=matrix(NA,nloc,ngroup)
for (i in 1:ngroup){
rasc=dat*matrix(log.phi[i,],nloc,nspp,byrow=T)+
n.minus.y*matrix(log.one.minus.phi[i,],nloc,nspp,byrow=T)
tmp[,i]=rowSums(rasc)+prior.prob[i]+log.theta[i] #sum log of prior probability
}
i=9
rasc=dat*matrix(log.phi[i,],nloc,nspp,byrow=T)+
n.minus.y*matrix(log.one.minus.phi[i,],nloc,nspp,byrow=T)
rasc
log.phi[i,16]
rm(list=ls(all=TRUE))
library('Rcpp')
set.seed(1)
setwd('U:\\GIT_models\\mixture_binom')
source('mixture gibbs functions.R')
sourceCpp('aux1.cpp')
source('mixture gibbs main function.R')
#get data
nl=read.csv('fake data mixture nl.csv',as.is=T)$x
y=read.csv('fake data mixture y.csv',as.is=T)
dat=data.matrix(y)
ngibbs=1000
burnin=ngibbs/2
ngroup=50
a.prior=b.prior=1
#useful pre-calculated quantities
nloc=nrow(dat)
nspp=ncol(dat)
nl.mat=matrix(nl,nloc,nspp)
n.minus.y=nl.mat-dat
constant=nspp*(lgamma(a.prior+b.prior)-lgamma(a.prior)-lgamma(b.prior))
#initial parameter values
z=sample(1:ngroup,size=nloc,replace=T)
theta=rep(1/ngroup,ngroup)
tmp=runif(ngroup*nspp)
phi=matrix(tmp,ngroup,nspp)
gamma1=0.1
gamma.possib=seq(from=0.1,to=1,by=0.05) #possible values for gamma
#to store results from gibbs sampler
store.phi=matrix(NA,ngibbs,nspp*ngroup)
store.theta=matrix(NA,ngibbs,ngroup)
store.z=matrix(NA,ngibbs,nloc)
store.gamma=matrix(NA,ngibbs,1)
store.logl=rep(NA,ngibbs)
#run gibbs sampler
for (i in 1:ngibbs){
print(i)
#sample group allocation vector z
z=update.z(dat=dat,nl=nl,n.minus.y=n.minus.y,phi=phi,theta=theta,
ngroup=ngroup,nloc=nloc,nspp=nspp,z=z,
a.prior=a.prior,b.prior=b.prior,constant=constant)
#re-order groups if necessary
#summarize the data
#determine the number of times a particular species was observed in each location group. This is ncs1
#determine the number of times a particular species was not observed in each location group. This is ncs0
tmp=ncs(dat=dat,nminusy=n.minus.y,z=z-1,nspp=nspp,nloc=nloc,ngroup=ngroup)
#sample the phi matrix containing the spp composition characterization of each group of locations
phi=matrix(rbeta(ngroup*nspp,tmp$ncs1+a.prior,tmp$ncs0+b.prior),ngroup,nspp)
#sample v and theta (this might also result in changes for z and phi)
tmp=update.theta(z=z,ngroup=ngroup,gamma1=gamma1,burnin=burnin,gibbs.step=i,theta=theta,phi=phi)
theta=tmp$theta
z=tmp$z
v=tmp$v
phi=tmp$phi
#sample the TSB parameter gamma
gamma1=sample.gamma(v=v,ngroup=ngroup,gamma.possib=gamma.possib)
#get loglikelihood
prob=phi[z,]
logl=dbinom(dat,size=nl.mat,prob=prob,log=T)
#store results
store.phi[i,]=phi
store.theta[i,]=theta
store.logl[i]=sum(logl)
store.z[i,]=z
store.gamma[i]=gamma1
}
traceback()
z=update.z(dat=dat,nl=nl,n.minus.y=n.minus.y,phi=phi,theta=theta,
ngroup=ngroup,nloc=nloc,nspp=nspp,z=z,
a.prior=a.prior,b.prior=b.prior,constant=constant)
log.theta=log(theta)
log.phi=log(phi)
log.one.minus.phi=log(1-phi)
range(log.theta)
range(log.phi)
range(log.one.minus.phi)
prior.prob=rowSums(dbeta(phi,a.prior,b.prior,log=T))
range(prior.prob)
tmp=matrix(NA,nloc,ngroup)
for (i in 1:ngroup){
rasc=dat*matrix(log.phi[i,],nloc,nspp,byrow=T)+
n.minus.y*matrix(log.one.minus.phi[i,],nloc,nspp,byrow=T)
tmp[,i]=rowSums(rasc)+prior.prob[i]+log.theta[i] #sum log of prior probability
}
tmp
range(tmp)
for (i in 1:nloc){
max.z=max(z)
prob=rep(NA,max.z)
prob=tmp[i,1:max.z]
if (max.z<ngroup){
log.p1=sum(lgamma(dat[i,]+a.prior)+lgamma(n.minus.y[i,]+b.prior)-lgamma(nl[i]+a.prior+b.prior))
tmp1=log.theta[i]+log.p1+constant
prob=c(prob,tmp1)
}
#get normalized probs
tmp1=prob-max(prob) #for numerical stability
tmp2=exp(tmp1) #exponentiate log probability
prob=tmp2/sum(tmp2) #normalize to sum to 1
#draw from multinomial distrib
ind=rmultinom(1,size=1,prob=prob)
ind1=which(ind==1)
z[i]=ind1
}
i
max.z=max(z)
max.z
max.z=max(z)
prob=rep(NA,max.z)
prob=tmp[i,1:max.z]
if (max.z<ngroup){
log.p1=sum(lgamma(dat[i,]+a.prior)+lgamma(n.minus.y[i,]+b.prior)-lgamma(nl[i]+a.prior+b.prior))
tmp1=log.theta[i]+log.p1+constant
prob=c(prob,tmp1)
}
prob
tmp1
log.p1
constant
log.theta[i]+log.p1+constant
log.theta[i]
log.theta
max.z=max(z)
prob=rep(NA,max.z)
prob=tmp[i,1:max.z]
if (max.z<ngroup){
log.p1=sum(lgamma(dat[i,]+a.prior)+lgamma(n.minus.y[i,]+b.prior)-lgamma(nl[i]+a.prior+b.prior))
tmp1=log.theta[max.z+1]+log.p1+constant
prob=c(prob,tmp1)
}
prob
tmp1=prob-max(prob) #for numerical stability
tmp2=exp(tmp1) #exponentiate log probability
prob=tmp2/sum(tmp2) #normalize to sum to 1
prob
rm(list=ls(all=TRUE))
library('Rcpp')
set.seed(1)
setwd('U:\\GIT_models\\mixture_binom')
source('mixture gibbs functions.R')
sourceCpp('aux1.cpp')
source('mixture gibbs main function.R')
#get data
nl=read.csv('fake data mixture nl.csv',as.is=T)$x
y=read.csv('fake data mixture y.csv',as.is=T)
dat=data.matrix(y)
ngibbs=1000
burnin=ngibbs/2
ngroup=50
a.prior=b.prior=1
#useful pre-calculated quantities
nloc=nrow(dat)
nspp=ncol(dat)
nl.mat=matrix(nl,nloc,nspp)
n.minus.y=nl.mat-dat
constant=nspp*(lgamma(a.prior+b.prior)-lgamma(a.prior)-lgamma(b.prior))
#initial parameter values
z=sample(1:ngroup,size=nloc,replace=T)
theta=rep(1/ngroup,ngroup)
tmp=runif(ngroup*nspp)
phi=matrix(tmp,ngroup,nspp)
gamma1=0.1
gamma.possib=seq(from=0.1,to=1,by=0.05) #possible values for gamma
#to store results from gibbs sampler
store.phi=matrix(NA,ngibbs,nspp*ngroup)
store.theta=matrix(NA,ngibbs,ngroup)
store.z=matrix(NA,ngibbs,nloc)
store.gamma=matrix(NA,ngibbs,1)
store.logl=rep(NA,ngibbs)
#run gibbs sampler
for (i in 1:ngibbs){
print(i)
#sample group allocation vector z
z=update.z(dat=dat,nl=nl,n.minus.y=n.minus.y,phi=phi,theta=theta,
ngroup=ngroup,nloc=nloc,nspp=nspp,z=z,
a.prior=a.prior,b.prior=b.prior,constant=constant)
#re-order groups if necessary
#summarize the data
#determine the number of times a particular species was observed in each location group. This is ncs1
#determine the number of times a particular species was not observed in each location group. This is ncs0
tmp=ncs(dat=dat,nminusy=n.minus.y,z=z-1,nspp=nspp,nloc=nloc,ngroup=ngroup)
#sample the phi matrix containing the spp composition characterization of each group of locations
phi=matrix(rbeta(ngroup*nspp,tmp$ncs1+a.prior,tmp$ncs0+b.prior),ngroup,nspp)
#sample v and theta (this might also result in changes for z and phi)
tmp=update.theta(z=z,ngroup=ngroup,gamma1=gamma1,burnin=burnin,gibbs.step=i,theta=theta,phi=phi)
theta=tmp$theta
z=tmp$z
v=tmp$v
phi=tmp$phi
#sample the TSB parameter gamma
gamma1=sample.gamma(v=v,ngroup=ngroup,gamma.possib=gamma.possib)
#get loglikelihood
prob=phi[z,]
logl=dbinom(dat,size=nl.mat,prob=prob,log=T)
#store results
store.phi[i,]=phi
store.theta[i,]=theta
store.logl[i]=sum(logl)
store.z[i,]=z
store.gamma[i]=gamma1
}
rm(list=ls(all=TRUE))
library('Rcpp')
set.seed(1)
setwd('U:\\GIT_models\\mixture_binom')
source('mixture gibbs functions.R')
sourceCpp('aux1.cpp')
source('mixture gibbs main function.R')
#get data
nl=read.csv('fake data mixture nl.csv',as.is=T)$x
y=read.csv('fake data mixture y.csv',as.is=T)
dat=data.matrix(y)
ngibbs=1000
burnin=ngibbs/2
ngroup=50
a.prior=b.prior=1
res=mixture.gibbs.main.func(dat=dat,nl=nl,ngroup=ngroup,ngibbs=ngibbs,burnin=burnin,
a.prior=a.prior,b.prior=b.prior)
theta=res$theta[nrow(res$theta),]
z=res$z[nrow(res$z),]
phi=matrix(res$phi[nrow(res$phi),],50,nspp)
theta=res$theta[nrow(res$theta),]
z=res$z[nrow(res$z),]
nspp=ncol(dat)
phi=matrix(res$phi[nrow(res$phi),],50,nspp)
plot(theta,type='h')
sum(theta>0.01)
table(z.true,z)
set.seed(1)
#general settings
nloc=100
nspp=20
ngroup=5
#set parameters
theta=rep(1/ngroup,ngroup)
tmp=rmultinom(nloc,size=1,prob=theta)
z.true=z=apply(tmp==1,2,which)
phi.true=phi=matrix(rbeta(ngroup*nspp,1,1),ngroup,nspp)
nl=rpois(nloc,lambda=2)+1; table(nl)
#generate data
y=matrix(NA,nloc,nspp)
for (i in 1:nloc){
phi1=phi[z[i],]
y[i,]=rbinom(nspp,size=nl[i],prob=phi1)
}
colnames(y)=paste0('spp',1:nspp)
rownames(y)=paste0('loc',1:nloc)
table(z.true,z)
k=table(z.true,z)
ind=numeric()
for (i in 1:nrow(k)){
tmp=which(z[i,]==max(z[i,]))
ind=c(ind,tmp)
}
ind
k=table(z.true,z)
ind=numeric()
for (i in 1:nrow(k)){
tmp=which(k[i,]==max(k[i,]))
ind=c(ind,tmp)
}
ind
k[,ind]
plot(phi.true,phi[ind,])
rm(list=ls(all=TRUE))
set.seed(1)
#general settings
nloc=1000
nspp=50
ngroup=8
#set parameters
theta=rep(1/ngroup,ngroup)
tmp=rmultinom(nloc,size=1,prob=theta)
z.true=z=apply(tmp==1,2,which)
phi.true=phi=matrix(rbeta(ngroup*nspp,1,1),ngroup,nspp)
nl=rpois(nloc,lambda=2)+1; table(nl)
#generate data
y=matrix(NA,nloc,nspp)
for (i in 1:nloc){
phi1=phi[z[i],]
y[i,]=rbinom(nspp,size=nl[i],prob=phi1)
}
colnames(y)=paste0('spp',1:nspp)
rownames(y)=paste0('loc',1:nloc)
#export results
setwd('U:\\GIT_models\\mixture_binom')
write.csv(y,'fake data mixture y.csv',row.names=F)
write.csv(nl,'fake data mixture nl.csv',row.names=F)
rm(list=ls(all=TRUE))
library('Rcpp')
set.seed(1)
setwd('U:\\GIT_models\\mixture_binom')
source('mixture gibbs functions.R')
sourceCpp('aux1.cpp')
source('mixture gibbs main function.R')
#get data
nl=read.csv('fake data mixture nl.csv',as.is=T)$x
y=read.csv('fake data mixture y.csv',as.is=T)
dat=data.matrix(y)
ngibbs=1000
burnin=ngibbs/2
ngroup=50
a.prior=b.prior=1
res=mixture.gibbs.main.func(dat=dat,nl=nl,ngroup=ngroup,ngibbs=ngibbs,burnin=burnin,
a.prior=a.prior,b.prior=b.prior)
rm(list=ls(all=TRUE))
set.seed(3)
#general settings
nloc=1000
nspp=50
ngroup=8
#set parameters
theta=rep(1/ngroup,ngroup)
tmp=rmultinom(nloc,size=1,prob=theta)
z.true=z=apply(tmp==1,2,which)
phi.true=phi=matrix(rbeta(ngroup*nspp,1,1),ngroup,nspp)
nl=rpois(nloc,lambda=2)+1; table(nl)
#generate data
y=matrix(NA,nloc,nspp)
for (i in 1:nloc){
phi1=phi[z[i],]
y[i,]=rbinom(nspp,size=nl[i],prob=phi1)
}
colnames(y)=paste0('spp',1:nspp)
rownames(y)=paste0('loc',1:nloc)
#export results
setwd('U:\\GIT_models\\mixture_binom')
write.csv(y,'fake data mixture y.csv',row.names=F)
write.csv(nl,'fake data mixture nl.csv',row.names=F)
rm(list=ls(all=TRUE))
library('Rcpp')
set.seed(10)
setwd('U:\\GIT_models\\mixture_binom')
source('mixture gibbs functions.R')
sourceCpp('aux1.cpp')
source('mixture gibbs main function.R')
#get data
nl=read.csv('fake data mixture nl.csv',as.is=T)$x
y=read.csv('fake data mixture y.csv',as.is=T)
dat=data.matrix(y)
ngibbs=1000
burnin=ngibbs/2
ngroup=50
a.prior=b.prior=1
res=mixture.gibbs.main.func(dat=dat,nl=nl,ngroup=ngroup,ngibbs=ngibbs,burnin=burnin,
a.prior=a.prior,b.prior=b.prior)
theta=res$theta[nrow(res$theta),]
z=res$z[nrow(res$z),]
nspp=ncol(dat)
phi=matrix(res$phi[nrow(res$phi),],50,nspp)
plot(theta,type='h')
sum(theta>0.01)
k=table(z.true,z);k
set.seed(3)
#general settings
nloc=1000
nspp=50
ngroup=8
#set parameters
theta=rep(1/ngroup,ngroup)
tmp=rmultinom(nloc,size=1,prob=theta)
z.true=z=apply(tmp==1,2,which)
phi.true=phi=matrix(rbeta(ngroup*nspp,1,1),ngroup,nspp)
nl=rpois(nloc,lambda=2)+1; table(nl)
#generate data
y=matrix(NA,nloc,nspp)
for (i in 1:nloc){
phi1=phi[z[i],]
y[i,]=rbinom(nspp,size=nl[i],prob=phi1)
}
colnames(y)=paste0('spp',1:nspp)
rownames(y)=paste0('loc',1:nloc)
k=table(z.true,z);k
k=table(z.true,z);k
ind=numeric()
for (i in 1:nrow(k)){
tmp=which(k[i,]==max(k[i,]))
ind=c(ind,tmp)
}
ind
k[,ind]
plot(phi.true,phi[ind,])
